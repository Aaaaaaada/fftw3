/* Generated by: ../../genfft/gen_notw_c -standalone -fma -reorder-insns -simd -compact -variables 100000 -with-ostride 2 -include fftw-spu.h -store-multiple 2 -n 4 -name X(spu_n2fv_4) */

/*
 * This function contains 8 FP additions, 2 FP multiplications,
 * (or, 6 additions, 0 multiplications, 2 fused multiply/add),
 * 15 stack variables, and 10 memory accesses
 */
/*
 * Generator Id's : 
 * $Id: algsimp.ml,v 1.9 2006-02-12 23:34:12 athena Exp $
 * $Id: fft.ml,v 1.4 2006-01-05 03:04:27 stevenj Exp $
 * $Id: gen_notw_c.ml,v 1.17 2006-02-12 23:34:12 athena Exp $
 */

#include "fftw-spu.h"

void X(spu_n2fv_4) (const R *ri, const R *ii, R *ro, R *io, stride is, stride os, INT v, INT ivs, INT ovs) {
     INT i;
     const R *xi;
     R *xo;
     xi = ri;
     xo = ro;
     for (i = v; i > 0; i = i - VL, xi = xi + (VL * ivs), xo = xo + (VL * ovs), MAKE_VOLATILE_STRIDE(is), MAKE_VOLATILE_STRIDE(os)) {
	  V T7, T3, T8, T6, T1, T2, T4, T5, T9, Ta, Tb, Tc;
	  T1 = LD(&(xi[0]), ivs, &(xi[0]));
	  T2 = LD(&(xi[WS(is, 2)]), ivs, &(xi[0]));
	  T7 = VADD(T1, T2);
	  T3 = VSUB(T1, T2);
	  T4 = LD(&(xi[WS(is, 1)]), ivs, &(xi[WS(is, 1)]));
	  T5 = LD(&(xi[WS(is, 3)]), ivs, &(xi[WS(is, 1)]));
	  T8 = VADD(T4, T5);
	  T6 = VSUB(T4, T5);
	  T9 = VFNMSI(T6, T3);
	  STM2(&(xo[2]), T9, ovs, &(xo[2]));
	  Ta = VADD(T7, T8);
	  STM2(&(xo[0]), Ta, ovs, &(xo[0]));
	  STN2(&(xo[0]), Ta, T9, ovs);
	  Tb = VFMAI(T6, T3);
	  STM2(&(xo[6]), Tb, ovs, &(xo[2]));
	  Tc = VSUB(T7, T8);
	  STM2(&(xo[4]), Tc, ovs, &(xo[0]));
	  STN2(&(xo[4]), Tc, Tb, ovs);
     }
}
